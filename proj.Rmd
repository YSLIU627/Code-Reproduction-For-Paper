---
title: "homework"
author: "LZH-XX"
date: "12/5/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


##1. The optimization target and their dual gap and dual residual

### Lasso

$\bar{g}_{i}^{*}\left(u_{i}\right)=\max _{\alpha_{i}:\left|\alpha_{i}\right| \leq B} u_{i} \alpha_{i}-\lambda\left|\alpha_{i}\right|=B\left[\left|u_{i}\right|-\lambda\right]_{+}$

```{r}
positive <- function(x){
  if(x >= 0){
    return(x)
  }
  return(0)
}

lasso.loss <- function(A,alpha,y) {
  # 返回loss函数的值
  return (norm(A%*%alpha - y,type = "2")+norm("alpha",type = "O"))
}

lasso.w_func <- function(alpha,A,y){
  #返回w的函数值
  return(2*(A %*% alpha - y))
}

lasso.subgrad <- function(alpha,lambda,A,dimension,y,...){
  #返回次梯度
  i <- dimension
  n <- length(alpha)
  alpha0 <- as.matrix(alpha)
  # First calculate the subgrad of |alpha|, sub1
  if (alpha[i] > 0 ){
    sub1 <- 1#alpha[i]/norm(alpha0,type = "O")
  }
  else if(alpha[i] < 0){
    sub1 <- -1#alpha[i]/norm(alpha0,type = "O")
  }
  else {
    seed <- runif(1,-1,1)
    sub1 <- lambda*seed #* alpha[i]/norm(alpha0,type = "O")
  }
  
  # Then calculate the grad of ||A\alpha -y||^2
  term <- vector(length =length(A[,1]))
  for (s in 1:n){
    term <- term + as.vector(alpha[s]*A[,s])
  }
  
  sub2 <- t(A[,i]) %*% term + t(term) %*% A[,i] - t(y) %*% A[,i] - t(A[,i])%*% y
  
  subgrad = sub1 +rowSums(sub2)
  #browser()
  return(subgrad)
}

lasso.gap <- function(alpha,lambda,B,A,dimension,y){
  # 计算对偶gap
  # A is a matrix
  i <- dimension
  #browser()
  w <- lasso.w_func(alpha,A,y)
  gap <- B*positive(abs(sum(A[,i]* w))- lambda)+lambda*abs(alpha[i])+
           alpha[i]*(sum(A[,i]* w))
  #browser()
  return(gap)
}
#CD_each_iter(sample_p = p.uniform,A =diag(1,3,3) ,y = diag(1,3,3)%*%c(1,0,1),lambda = 0.05)
lasso.dualres <- function(alpha,lambda,A,dimension,y){
  #计算对偶残差
  # first calculate the subgrad of g_i^*
  i <- dimension
  flag <-  0
  eps <- 1e-5
  w <- lasso.w_func(alpha, A, y)
  input <- -t(A[,i])%*%w
  # 这里的g用的是文中修改后的g拔，下面计算次梯度
  if (input > eps && input <= B){
    g_sub <- lambda *input
  }
  else if(input < -eps && input >= -B){
    g_sub <- -lambda *input
  }
  else if(abs(input) <B){
    g_sub_right <- lambda * abs(input)
    g_sub_left  <- -lambda * abs(input)
    flag <- 1 
    #g_sub is an interval
  }
  else {
    g_sub <- Inf
  }
    
  # When flag ==0 ,subgrad is grad, otherwise is a interval
  if (flag == 0){
      return (abs(alpha[i])-g_sub)
  }
  #  subgrad is a interval
  if (abs(alpha[i]) <= g_sub_right){
    return (0)
  }
  else {
    return (min(abs(alpha[i]-g_sub_right),abs(alpha[i]-g_sub_left) ))
    # Return the closet distance from the interval
  }
  
  
}

#CD_each_iter(sample_p = p.uniform,A = A.mushrooms,y = y.mushrooms,lambda = 0.05)

```


##2.Adaptive Sampling -based CD 

###2.1 Gap-wise
```{r}

p.ada.gap <- function(alpha,lambda,B,A,y){
  n <- length(alpha)
  p <- numeric(length = n)
  
  for (i in 1:n){
    p[i] <- lasso.gap(alpha, lambda, B, A, i, y)
  }
  #browser()
  psum <- sum(p) 
  for (i in 1:n){
    p[i] <- p[i]/psum
  }
  
  return(p)
}

```

###2.2 Adaptive

```{r}
p.ada.uniform <- function(alpha, lamda, A, y, sigma,B){
  n <- length(alpha)
  p <- numeric(length = n)
  second_term <- numeric(length = n)
  eps <- 1e-5
  m <- n
  for (i in 1:n){
    k <- abs(lasso.dualres(alpha, lambda, A, i,y))
    if( k < eps){
      p[i] <- 0
      m <- m-1
    }
    second_term[i] <- k*norm(A[,i],type ="F")
  }
  
  second_term <- second_term/sum(second_term)
  
  for (i in 1:n){
    if (p[i] > 0){
      p[i] <- sigma/m + second_term*(1-sigma)
      }
  }
  return(p)
}

```


###2.3 Uniform

```{r}
p.uniform <- function(alpha,A,y,lambda,B){
  n <- length(alpha)
  p <- numeric(length = n)
  for (i in 1:n){
    p[i] <- 1/n
  }
  return(p)
}

```

###2.4 Importance Sampling

```{r}
p.imp <- function(alpha,A,y,lambda,B){
  n <- length(alpha)
  p <- numeric(length = n)
  for (i in 1:n){
    p[i] <- norm(A[,i],type = "F")
  }
  p = p/sum(p)
  return(p)
}


```


##3.Coordinate descdent

```{r}

CD_each_iter <- function(sample_p,A,y,lambda,...)
  {
  step0 <- 0.01
  epoch <- dim(A)[2]
  n <- dim(A)[2]
  max_iter <- epoch*25
  record.gap <- numeric(length=25)
  gap <- numeric(n)
  # A,y are given data
  alpha <- numeric(length = n)
  B <- (norm(A%*%alpha - y,type = "2"))/lambda
  w <- lasso.w_func(alpha,A,y)
  iter <- 0
  while(iter < max_iter){
  iter <- iter+1
  i <- sample(1:n,size = 1,prob = sample_p(alpha = alpha,A=A,y=y,lambda=lambda,B=B,...))
  # direction is a sample prob vector like alpha with only one none zero dim
  direction = vector(length = n)
  direction[i] = 1
  update <- direction * lasso.subgrad(alpha = alpha,dimension =i ,A =A,y=y,lambda = lambda)
  alpha <- alpha - step0/sqrt(iter)*update
  #browser()
  # Record the result
  if(iter%%epoch==0){
    k <- iter/epoch
    for(j in 1:n){
      gap[j] <- lasso.gap(alpha, lambda, B, A, j,y=y)
    }
    record.gap[k] <- sum(gap)
    #browser()
  }
  }
  return (log(record.gap))
}
#CD_each_iter(sample_p = p.uniform,A = A.mushrooms,y = y.mushrooms,lambda = 0.05)
CD_per_epoch <-function(sample_p,A,y,lambda, ...)
  {
  epoch <- dim(A)[2]
  n <- dim(A)[2]
  max_iter <- epoch*25
  record.gap <- numeric(length=25)
  gap <- numeric(n)
  # A,y are given data
  alpha <- numeric(length = n)
  B <- (norm(A%*%alpha - y,type = "2"))/lambda
  w <- lasso.w_func(alpha,A,y)
  iter <- 0
  p <- sample_p(alpha = alpha,A=A,y=y,lambda=lambda,B=B,...)
  while(iter < max_iter){
  iter <- iter+1
  i <- sample(1:n,prob = p)
  # direction is a sample prob vector like alpha with only one none zero dim
  direction = vector(length = n)
  direction[i] = 1
  update <- direction * lasso.subgrad(alpha = alpha,dimension =i ,A =A,y=y,lambda = lambda)
  alpha <- alpha - update
  # Record the result
  if(iter%%epoch==0){
    k <- iter/epoch
    for(j in 1:n){
      gap[j] <- lasso.gap(alpha, lambda, B, A, j,y)
    }
    record.gap[k] <- sum(gap)
    p <- sample_p(alpha = alpha,A=A,y=y,lambda=lambda,B=B,...)
  }
  }
  return (log(record.gap))
}
```




##4.Exmperiment

Collect data
```{r}
mushrooms <- readLines("https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/mushrooms")
rcv1 <- readLines("rcv1_train.binary")
```
Get corresponding A and y
```{r}
A.mushrooms <- matrix(0,nrow = 8124, ncol = 112)
y.mushrooms <- numeric(length = 112)
a <- strsplit(mushrooms, split = " ")
for(i in 1:8124){
  b <- a[[i]]
  y.mushrooms[i] <- as.numeric(b[1])
  b <- b[-1]
  len <- length(b)
  c <- strsplit(b,split = ":")
  for(j in 1:len){
    colind <- c[[j]][1]
    val <- c[[j]][2]
    colind <- as.numeric(colind)
    val <- as.numeric(val)
    A.mushrooms[i,colind] <- val
  }
}
```

```{r}
set.seed(1)
ind <- sample(1:20242, 10000)
feature <- sample(1:50000, 1000)
feature <- as.character(sort(feature))
rcv1 <- rcv1[ind]
A.rcv1 <- matrix(0,nrow = 10000, ncol = 1000)
colnames(A.rcv1) <- feature
y.rcv1 <- numeric(length = 10000)
a <- strsplit(rcv1, split = " ")
for(i in 1:10000){
  b <- a[[i]]
  y.rcv1[i] <- as.numeric(b[1])
  b <- b[-1]
  len <- length(b)
  c <- strsplit(b,split = ":")
  for(j in 1:len){
    colind <- c[[j]][1]
    if(sum(colind==feature)==1){
      val <- c[[j]][2]
      val <- as.numeric(val)
      A.rcv1[i,colind] <- val
    }
  }
}
```
remove rows and columns that are full of 0 in A.rcv1
```{r}
rs<-apply(A.rcv1,1,sum)
A.rcv1 <- A.rcv1[which(rs!=0),]
y.rcv1 <- y.rcv1[which(rs!=0)]
cs <- apply(A.rcv1,2,sum)
A.rcv1 <- A.rcv1[,which(cs!=0)]
```
example
```{r}
CD_each_iter(sample_p = p.uniform,A = A.mushrooms,y = y.mushrooms,lambda = 0.05)
```

## 5.Plot


